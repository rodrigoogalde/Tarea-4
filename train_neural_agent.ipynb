{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento de los agentes basados en redes neuronales\n",
    "\n",
    "Para entrenar a los agentes, deberemos definir un set de datos con estados del juego y un set de etiquetas con la acci칩n preferida (representada en un vector de largo 5 con ceros en todas las posiciones excepto la de la acci칩n elegida).\n",
    "\n",
    "Luego, entrenaremos la red neuronal en este set de datos y la guardaremos en un archivo (``NN[Agent].h5``), el cual podr치 ser accedido por el agente en el archivo ``neural.py``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librer칤as utilizadas para trabajar en el notebook\n",
    "import tensorflow as tf # Instalar mediante pip install tensorflow\n",
    "import numpy as np\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones auxiliares (que pueden resultar 칰tiles) y rival de baseline, entregado con la tarea\n",
    "from agents.baseline import BaseCat, BaseMouse\n",
    "from utils import bfs_search, get_valid_moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el mapa de juego, para poder buscar espacios libres dentro de 칠l\n",
    "lab_map = np.load(os.path.join(\"game_map.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0), (0, 1), (0, 2), (0, 3), (0, 4)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtenemos los espacios libres dentro del mapa\n",
    "free_positions = []\n",
    "\n",
    "for x in range(lab_map.shape[0]):\n",
    "    for y in range(lab_map.shape[1]):\n",
    "        if lab_map[x, y] == 0:\n",
    "            free_positions.append((x, y))\n",
    "\n",
    "free_positions[:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento del gato 游낻"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creaci칩n del set de datos\n",
    "\n",
    "Generaremos un set de datos ``X`` que contendr치 numpy arrays con la posici칩n del gato y el rat칩n ``(cat_pos[0], cat_pos[1], mouse_pos[0], mouse_pos[1])``.\n",
    "\n",
    "Adem치s, generaremos un set de etiquetas ``y`` que contendr치 numpy arrays con el movimiento a realizar (ej. ``(0, 0, 1, 0, 0)`` significa hacer el movimiento 2).\n",
    "\n",
    "La forma en que calculas qu칠 acci칩n llevar a cabo dado el estado de juego es tu decisi칩n, puede ser una b칰squeda utilizando el algoritmo de BFS entregado, una pol칤tica manual o una serie de reglas if-else. Lo importante es que este ser치 el comportamiento que la red neuronal del agente tratar치 de aproximar. Recuerda que dispones del mapa de juego en ``lab_map`` y de un agente contra el que entrenar bajo la clase `BaseMouse`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciamos al jugador oponente\n",
    "rival = BaseMouse((0, 0))\n",
    "\n",
    "# Trabajaremos a X e y como listas, en la siguiente celda las transformaremos a un array de numpy\n",
    "# (los componentes que colocas en ellas si deben ser numpy arrays)\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# Para cada combinaci칩n de posiciones de gato y rat칩n\n",
    "for cat_pos in free_positions:\n",
    "    for mouse_pos in free_positions:\n",
    "        X.append(np.array([cat_pos[0], cat_pos[1], mouse_pos[0], mouse_pos[1]]))\n",
    "\n",
    "        # ===== COMPLETAR =====\n",
    "        # Se debe calcular un vector de accion, correspondiente a la decisi칩n a tomar para a침adirlo a la lista y\n",
    "        label = np.zeros((5))   # Actualmente se trata de un vector de solo ceros, se debe reemplazar la posici칩n del movimiento elegido por un 1\n",
    "        # =====================\n",
    "\n",
    "        # # Convertimos las posiciones a arrays de numpy\n",
    "        cat_pos_np = np.array(cat_pos)\n",
    "        mouse_pos_np = np.array(mouse_pos)\n",
    "\n",
    "        # Obtenemos la acci칩n que tomar칤a el gato y el rat칩n\n",
    "        mouse_action = rival.get_action(lab_map, cat_pos_np, mouse_pos_np)\n",
    "\n",
    "        # Representamos las acciones en formato one-hot\n",
    "        label[mouse_action] = 1\n",
    "\n",
    "        # A침adimos las etiquetas a la lista y\n",
    "        y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6561, 6561)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformamos las listas a numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dise침o y entrenamiento de la Red Neuronal\n",
    "\n",
    "Para entrenar nuestra red neuronal, utilizaremos la librer칤a de [`TensorFlow`](https://www.tensorflow.org/api_docs/python/tf/all_symbols), podemos instalar esta librer칤a mediante la l칤nea `pip install tensorflow`.\n",
    "\n",
    "TensorFlow es una librer칤a desarrollada por Google que nos permite construir, entrenar e implementar modelos de aprendizaje profundo en Python.\n",
    "\n",
    "Para esto, TensorFlow nos permite armar una red en forma de \"capas\", [en el siguiente link encontrar치s un tutorial m치s en detalle de c칩mo crear un modelo de TensorFlow](https://towardsdatascience.com/building-our-first-neural-network-in-keras-bdc8abbc17f5). Deberemos introducir todas las capas de nuestra red dentro de un objeto `tf.keras.Sequential()`, que recibe de par치metro una lista con todos los elementos de nuestra red.\n",
    "\n",
    "<br>\n",
    "\n",
    "A continuaci칩n se enumeran los tres principales elementos que utilizaremos en nuestro modelo:\n",
    "- `tf.keras.Input(shape = a)`: La capa de entrada de la red, es la primera que recibe. Necesita de un par치metro `shape` que determinar치 la dimensionalidad del vector de entrada, esto ser치 entregado en una tupla `a` (ej. `(5, 2)`).\n",
    "\n",
    "- `tf.keras.layers.Dense(units = b, activation = 'relu')`: Corresponde a una capa intermedia de la red del tipo *Fully Connected*, le entregaremos un par치metro `units` que determinar치 cu치ntas unidades ocultas (neuronas) tendr치 la capa (y por tanto, el n칰mero de componentes en el vector de salida de la capa, en este caso `b`). Adem치s, recibir치 una funci칩n de activaci칩n para cada neurona, esta puede ser del tipo `relu`, `tanh`, `softmax` u otras, para m치s detalle sobre ellas visitar [el siguiente link](https://www.tensorflow.org/api_docs/python/tf/keras/activations). Recomendamos usar `relu` para capas intermedias.\n",
    "\n",
    "- `tf.keras.layers.Dense(units = c, activation = 'softmax')`: Similar a lo explicado anteriormente, corresponde a una capa densa de activaci칩n `softmax`. Esta corresponder치 a la capa final del modelo, con `c` el n칰mero de elementos que deseamos que nuestro vector de salida tenga. El uso de una funci칩n softmax se debe a que esta nos permite llevar la salida de nuestra neurona a un conjunto de probabilidades normalizadas, desde el cual podemos calcular qu칠 acci칩n jugar. [En el siguiente link](https://deepai.org/machine-learning-glossary-and-terms/softmax-layer) se explica el funcionamiento de esta funci칩n en mayor detalle.\n",
    "\n",
    "<br>\n",
    "\n",
    "Un ejemplo de una red simple ser칤a:\n",
    "```\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape = a),\n",
    "    tf.keras.layers.Dense(b, activation = \"relu\"),\n",
    "    tf.keras.layers.Dense(c, activation = \"softmax\")\n",
    "])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recuerda que para esta tarea la entrada es un vector de 4 elementos y buscamos una salida de 5 elementos (la probabilidad de jugar acci칩n posible)\n",
    "\n",
    "# ===== COMPLETAR =====\n",
    "# Se debe crear un modelo para nuestra red neuronal, a침ade cuantas capas ocultas desees, con cuantas neuronas desees\n",
    "# model = tf.keras.Sequential([])\n",
    "# =====================\n",
    "\n",
    "# Creaci칩n del modelo de red neuronal\n",
    "model = tf.keras.Sequential([\n",
    "    # Capa de entrada\n",
    "    tf.keras.Input(shape=(4,)),  # La entrada es un vector de 4 elementos\n",
    "\n",
    "    # Capas ocultas\n",
    "    tf.keras.layers.Dense(50, activation='relu'),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(500, activation='relu'),\n",
    "    tf.keras.layers.Dense(900, activation='relu'),\n",
    "    tf.keras.layers.Dense(10),\n",
    "\n",
    "    # Capa de salida\n",
    "    tf.keras.layers.Dense(5, activation=\"softmax\")  # La salida es un vector de 5 elementos (probabilidad para cada acci칩n)\n",
    "])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow nos permite adem치s compilar un modelo, especificando qu칠 optimizador utilizar para su ajuste de par치metros y qu칠 funci칩n de p칠rdida utilizar para hacer la backpropagation.\n",
    "\n",
    "Compilaremos un modelo de la forma:\n",
    "``model.compile(optimizer = 'optimizer_name', loss = 'loss_name', metrics = ['accuracy'])``\n",
    "\n",
    "- Con `optimizer_name` el nombre de alg칰n optimizador (por ejemplo, `sgd` o `adam`, m치s optimizadores en el [siguiente link](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers))\n",
    "- Con `loss_name` el nombre de alguna funci칩n de p칠rdida (por ejemplo, `binary_crossentropy`, m치s funciones en el [siguiente link](https://www.tensorflow.org/api_docs/python/tf/keras/losses))\n",
    "- Usaremos de m칠trica el accuracy del modelo, aunque existe [m칰ltiples otras m칠tricas que incluir](https://www.tensorflow.org/api_docs/python/tf/keras/metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== COMPLETAR =====\n",
    "# Compila tu modelo de TensorFlow\n",
    "# model\n",
    "# =====================\n",
    "\n",
    "# Compilaci칩n del modelo\n",
    "model.compile(\n",
    "    optimizer='adam',  # Optimizador\n",
    "    loss='categorical_crossentropy',  # Funci칩n de p칠rdida\n",
    "    metrics=['accuracy']  # M칠tricas para monitorear durante el entrenamiento\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que especificamos c칩mo vamos calcular el error del modelo y c칩mo lo usaremos para ajustar sus pesos, es hora de entrenar nuestra red. Para ello, utilizaremos su m칠todo `.fit()` de la siguiente forma:\n",
    "\n",
    "`model.fit(X, y, epochs = a, batch_size = b)`\n",
    "\n",
    "- `X` corresponde a nuestra matriz de caracter칤sticas\n",
    "- `y` corresponde a nuestro vector de etiquetas para cada muestra\n",
    "- `epochs` determina cu치ntas veces iteraremos sobre todo el set de datos\n",
    "- `batch_size` determina cu치ntas muestras ser치n consideradas por propagaci칩n del gradiente (un valor mayor significa entrenamiento m치s r치pido pero mayor uso de memoria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 0.1606 - accuracy: 0.9354\n",
      "Epoch 2/30\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1241 - accuracy: 0.9560\n",
      "Epoch 3/30\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 0.1163 - accuracy: 0.9587\n",
      "Epoch 4/30\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.0951 - accuracy: 0.9688\n",
      "Epoch 5/30\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.0807 - accuracy: 0.9776\n",
      "Epoch 6/30\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.0775 - accuracy: 0.9784\n",
      "Epoch 7/30\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 0.0746 - accuracy: 0.9803\n",
      "Epoch 8/30\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 0.0703 - accuracy: 0.9800\n",
      "Epoch 9/30\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 0.0677 - accuracy: 0.9819\n",
      "Epoch 10/30\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 0.0669 - accuracy: 0.9825\n",
      "Epoch 11/30\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 0.0640 - accuracy: 0.9849\n",
      "Epoch 12/30\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 0.0693 - accuracy: 0.9813\n",
      "Epoch 13/30\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 0.0656 - accuracy: 0.9816\n",
      "Epoch 14/30\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 0.0618 - accuracy: 0.9835\n",
      "Epoch 15/30\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 0.0589 - accuracy: 0.9864\n",
      "Epoch 16/30\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 0.0616 - accuracy: 0.9860\n",
      "Epoch 17/30\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 0.0662 - accuracy: 0.9834\n",
      "Epoch 18/30\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 0.0749 - accuracy: 0.9784\n",
      "Epoch 19/30\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 0.0669 - accuracy: 0.9826\n",
      "Epoch 20/30\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 0.0652 - accuracy: 0.9825\n",
      "Epoch 21/30\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 0.0631 - accuracy: 0.9826\n",
      "Epoch 22/30\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 0.0703 - accuracy: 0.9791\n",
      "Epoch 23/30\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 0.0690 - accuracy: 0.9796\n",
      "Epoch 24/30\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 0.0705 - accuracy: 0.9808\n",
      "Epoch 25/30\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 0.0670 - accuracy: 0.9820\n",
      "Epoch 26/30\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 0.0593 - accuracy: 0.9845\n",
      "Epoch 27/30\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 0.0588 - accuracy: 0.9846\n",
      "Epoch 28/30\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 0.0588 - accuracy: 0.9849\n",
      "Epoch 29/30\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 0.0548 - accuracy: 0.9858\n",
      "Epoch 30/30\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 0.0604 - accuracy: 0.9822\n"
     ]
    }
   ],
   "source": [
    "# ===== COMPLETAR =====\n",
    "# Entrena tu modelo de TensorFlow utilizando su m칠todo .fit()\n",
    "# model\n",
    "# =====================\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "history = model.fit(\n",
    "    X,  # Matriz de caracter칤sticas\n",
    "    y,  # Vector de etiquetas\n",
    "    epochs=30,  # N칰mero de 칠pocas\n",
    "    batch_size=512  # Tama침o del lote\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por 칰ltimo, guardaremos el modelo entrenado en el directorio `agents/data/NNCat.h5` para poder acceder a este modelo desde nuestra clase `NNCat`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rodrigo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save(os.path.join('agents', 'data', 'NNCat.h5'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento del rat칩n 游내"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creaci칩n del set de datos\n",
    "\n",
    "Generaremos un set de datos ``X`` que contendr치 numpy arrays con la posici칩n del gato y el rat칩n ``(cat_pos[0], cat_pos[1], mouse_pos[0], mouse_pos[1])``.\n",
    "\n",
    "Adem치s, generaremos un set de etiquetas ``y`` que contendr치 numpy arrays con el movimiento a realizar (ej. ``(1, 0, 0, 0, 0)`` significa hacer el movimiento 0).\n",
    "\n",
    "La forma en que calculas qu칠 acci칩n llevar a cabo dado el estado de juego es tu decisi칩n. Lo importante es que este ser치 el comportamiento que la red neuronal del agente tratar치 de aproximar. Recuerda que dispones del mapa de juego en ``lab_map`` y de un agente contra el que entrenar bajo la clase `BaseCat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciamos al jugador oponente\n",
    "rival = BaseCat((0, 0))\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for cat_pos in free_positions:\n",
    "    for mouse_pos in free_positions:\n",
    "        X.append(np.array([cat_pos[0], cat_pos[1], mouse_pos[0], mouse_pos[1]]))\n",
    "\n",
    "        # ===== COMPLETAR =====\n",
    "        # Se debe calcular un vector de accion, correspondiente a la decisi칩n a tomar para a침adirlo a la lista y\n",
    "        # label = np.zeros((5))   # Actualmente se trata de un vector de solo ceros, se debe reemplazar la posici칩n del movimiento elegido por un 1\n",
    "        # =====================\n",
    "\n",
    "        # Calculamos la acci칩n que tomar칤a el gato\n",
    "        cat_action = rival.get_action(lab_map, cat_pos, mouse_pos)\n",
    "\n",
    "        # Representamos la acci칩n en formato one-hot\n",
    "        label = np.zeros((5))\n",
    "        label[cat_action] = 1\n",
    "\n",
    "        y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6561 6561\n"
     ]
    }
   ],
   "source": [
    "print(len(X), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformamos las listas a numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dise침o y entrenamiento de la Red Neuronal\n",
    "\n",
    "Para entrenar nuestra red neuronal, utilizaremos la librer칤a de [`TensorFlow`](https://www.tensorflow.org/api_docs/python/tf/all_symbols), podemos instalar esta librer칤a mediante la l칤nea `pip install tensorflow`.\n",
    "\n",
    "TensorFlow es una librer칤a desarrollada por Google que nos permite construir, entrenar e implementar modelos de aprendizaje profundo en Python.\n",
    "\n",
    "Para esto, TensorFlow nos permite armar una red en forma de \"capas\", [en el siguiente link encontrar치s un tutorial m치s en detalle de c칩mo crear un modelo de TensorFlow](https://towardsdatascience.com/building-our-first-neural-network-in-keras-bdc8abbc17f5). Deberemos introducir todas las capas de nuestra red dentro de un objeto `tf.keras.Sequential()`, que recibe de par치metro una lista con todos los elementos de nuestra red.\n",
    "\n",
    "<br>\n",
    "\n",
    "A continuaci칩n se enumeran los tres principales elementos que utilizaremos en nuestro modelo:\n",
    "- `tf.keras.Input(shape = a)`: La capa de entrada de la red, es la primera que recibe. Necesita de un par치metro `shape` que determinar치 la dimensionalidad del vector de entrada, esto ser치 entregado en una tupla `a` (ej. `(5, 2)`).\n",
    "\n",
    "- `tf.keras.layers.Dense(units = b, activation = 'relu')`: Corresponde a una capa intermedia de la red del tipo *Fully Connected*, le entregaremos un par치metro `units` que determinar치 cu치ntas unidades ocultas (neuronas) tendr치 la capa (y por tanto, el n칰mero de componentes en el vector de salida de la capa, en este caso `b`). Adem치s, recibir치 una funci칩n de activaci칩n para cada neurona, esta puede ser del tipo `relu`, `tanh`, `softmax` u otras, para m치s detalle sobre ellas visitar [el siguiente link](https://www.tensorflow.org/api_docs/python/tf/keras/activations). Recomendamos usar `relu` para capas intermedias.\n",
    "\n",
    "- `tf.keras.layers.Dense(units = c, activation = 'softmax')`: Similar a lo explicado anteriormente, corresponde a una capa densa de activaci칩n `softmax`. Esta corresponder치 a la capa final del modelo, con `c` el n칰mero de elementos que deseamos que nuestro vector de salida tenga. El uso de una funci칩n softmax se debe a que esta nos permite llevar la salida de nuestra neurona a un conjunto de probabilidades normalizadas, desde el cual podemos calcular qu칠 acci칩n jugar. [En el siguiente link](https://deepai.org/machine-learning-glossary-and-terms/softmax-layer) se explica el funcionamiento de esta funci칩n en mayor detalle.\n",
    "\n",
    "<br>\n",
    "\n",
    "Un ejemplo de una red simple ser칤a:\n",
    "```\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape = a),\n",
    "    tf.keras.layers.Dense(b, activation = \"relu\"),\n",
    "    tf.keras.layers.Dense(c, activation = \"softmax\")\n",
    "])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recuerda que para esta tarea la entrada es un vector de 4 elementos y buscamos una salida de 5 elementos (la probabilidad de jugar acci칩n posible)\n",
    "\n",
    "# ===== COMPLETAR =====\n",
    "# Se debe crear un modelo para nuestra red neuronal, a침ade cuantas capas ocultas desees, con cuantas neuronas desees\n",
    "# model = tf.keras.Sequential([])\n",
    "# =====================\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    # Capa de entrada\n",
    "    tf.keras.Input(shape=(4,)),  # La entrada es un vector de 4 elementos\n",
    "\n",
    "    # Capas ocultas\n",
    "    # tf.keras.layers.Dense(32, activation=\"relu\"),  # Primera capa oculta con 32 neuronas\n",
    "    # tf.keras.layers.Dense(64, activation=\"relu\"),  # Segunda capa oculta con 64 neuronas\n",
    "    # tf.keras.layers.Dense(128, activation=\"relu\"),  # Tercera capa oculta con 128 neuronas \n",
    "    tf.keras.layers.Dense(50, activation='relu'),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(500, activation='relu'),\n",
    "\n",
    "    # Capa de salida\n",
    "    tf.keras.layers.Dense(5, activation=\"softmax\")  # La salida es un vector de 5 elementos (probabilidad para cada acci칩n)\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow nos permite adem치s compilar un modelo, especificando qu칠 optimizador utilizar para su ajuste de par치metros y qu칠 funci칩n de p칠rdida utilizar para hacer la backpropagation.\n",
    "\n",
    "Compilaremos un modelo de la forma:\n",
    "``model.compile(optimizer = 'optimizer_name', loss = 'loss_name', metrics = ['accuracy'])``\n",
    "\n",
    "- Con `optimizer_name` el nombre de alg칰n optimizador (por ejemplo, `sgd` o `adam`, m치s optimizadores en el [siguiente link](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers))\n",
    "- Con `loss_name` el nombre de alguna funci칩n de p칠rdida (por ejemplo, `binary_crossentropy`, m치s funciones en el [siguiente link](https://www.tensorflow.org/api_docs/python/tf/keras/losses))\n",
    "- Usaremos de m칠trica el accuracy del modelo, aunque existe [m칰ltiples otras m칠tricas que incluir](https://www.tensorflow.org/api_docs/python/tf/keras/metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== COMPLETAR =====\n",
    "# Compila tu modelo de TensorFlow\n",
    "# model\n",
    "# =====================\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',  # Optimizador\n",
    "    loss='categorical_crossentropy',  # Funci칩n de p칠rdida\n",
    "    metrics=['accuracy']  # M칠tricas para monitorear durante el entrenamiento\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que especificamos c칩mo vamos calcular el error del modelo y c칩mo lo usaremos para ajustar sus pesos, es hora de entrenar nuestra red. Para ello, utilizaremos su m칠todo `.fit()` de la siguiente forma:\n",
    "\n",
    "`model.fit(X, y, epochs = a, batch_size = b)`\n",
    "\n",
    "- `X` corresponde a nuestra matriz de caracter칤sticas\n",
    "- `y` corresponde a nuestro vector de etiquetas para cada muestra\n",
    "- `epochs` determina cu치ntas veces iteraremos sobre todo el set de datos\n",
    "- `batch_size` determina cu치ntas muestras ser치n consideradas por propagaci칩n del gradiente (un valor mayor significa entrenamiento m치s r치pido pero mayor uso de memoria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0662 - accuracy: 0.9761\n",
      "Epoch 2/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0712 - accuracy: 0.9733\n",
      "Epoch 3/20\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.0732 - accuracy: 0.9720\n",
      "Epoch 4/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0748 - accuracy: 0.9736\n",
      "Epoch 5/20\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.1024 - accuracy: 0.9596\n",
      "Epoch 6/20\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0869 - accuracy: 0.9672\n",
      "Epoch 7/20\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0672 - accuracy: 0.9779\n",
      "Epoch 8/20\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0634 - accuracy: 0.9774\n",
      "Epoch 9/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0639 - accuracy: 0.9767\n",
      "Epoch 10/20\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0607 - accuracy: 0.9785\n",
      "Epoch 11/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0603 - accuracy: 0.9794\n",
      "Epoch 12/20\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0610 - accuracy: 0.9784\n",
      "Epoch 13/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0588 - accuracy: 0.9794\n",
      "Epoch 14/20\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.0609 - accuracy: 0.9799\n",
      "Epoch 15/20\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.0604 - accuracy: 0.9806\n",
      "Epoch 16/20\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0632 - accuracy: 0.9779\n",
      "Epoch 17/20\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0678 - accuracy: 0.9733\n",
      "Epoch 18/20\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.0599 - accuracy: 0.9794\n",
      "Epoch 19/20\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0564 - accuracy: 0.9813\n",
      "Epoch 20/20\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0565 - accuracy: 0.9816\n"
     ]
    }
   ],
   "source": [
    "# ===== COMPLETAR =====\n",
    "# Entrena tu modelo de TensorFlow utilizando su m칠todo .fit()\n",
    "# model\n",
    "# =====================\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "history = model.fit(\n",
    "    X,  # Matriz de caracter칤sticas\n",
    "    y,  # Vector de etiquetas\n",
    "    epochs=20,  # N칰mero de 칠pocas\n",
    "    batch_size=256  # Tama침o del lote\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por 칰ltimo, guardaremos el modelo entrenado en el directorio `agents/data/NNMouse.h5` para poder acceder a este modelo desde nuestra clase `NNMouse`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join('agents', 'data', 'NNMouse.h5'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Todas las respuestas a las preguntas se encuentran en el pdf IA_T4.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
